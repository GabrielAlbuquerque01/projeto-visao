{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fdb302f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from constants import PATH_JSON_ANNOTATIONS, PATH_JSON_QUESTIONS, OPENAI_KEY, PROMPT_CONSTRUCAO_TEXTO, PROMPT_MIX_RESPONSE, PROMPT_SANITY_CHECK\n",
    "import torch\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from transformers import BitsAndBytesConfig\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c8a219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "GPU atual: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# verificando se GPU está disponível\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(\"GPU atual:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Nenhuma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1562605",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b809b7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "c:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\gabri\\.cache\\huggingface\\hub\\models--Qwen--Qwen2-VL-2B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Exception in thread Thread-5 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\subprocess.py\", line 1515, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "  File \"c:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc6 in position 8: invalid continuation byte\n",
      "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Error while downloading from https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/895c3a49bc3fa70a340399125c650a463535e71c/model-00001-of-00002.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    }
   ],
   "source": [
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-2B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\", quantization_config=quantization_config\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32693b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\",\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Preparation for inference\n",
    "text = processor.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "image_inputs, video_inputs = process_vision_info(messages)\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=image_inputs,\n",
    "    videos=video_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = inputs.to(\"cuda\")\n",
    "\n",
    "# Inference: Generation of the output\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac4a21",
   "metadata": {},
   "source": [
    "## Generate answers functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "886ff520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers_image_only(df: pd.DataFrame, model):\n",
    "\n",
    "    answers = []\n",
    "    model_df = df.copy()\n",
    "    base_image_path = 'images/'\n",
    "\n",
    "    for i in model_df.index:\n",
    "        image_infos = model_df.iloc[i]\n",
    "        image_question = image_infos['question']\n",
    "        image_path = base_image_path + image_infos['image_path']\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        prompt_text = image_question + '' + 'Respond only with the final answer, without explanation or full sentences.'\n",
    "\n",
    "        prompt_image_only = f\"[INST] <image>\\n{prompt_text} [/INST]\"\n",
    "\n",
    "        inputs = processor(\n",
    "            text=prompt_image_only,\n",
    "            images=image,\n",
    "            return_tensors=\"pt\",\n",
    "            # padding=True\n",
    "        ).to(model.device)\n",
    "\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=100,\n",
    "            pad_token_id=processor.tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        answer = processor.decode(\n",
    "            output[0],\n",
    "            skip_special_tokens=True,\n",
    "        ).replace(image_question, \"\").strip()\n",
    "\n",
    "        if \"[/INST]\" in answer:\n",
    "            answer = answer.split(\"[/INST]\")[-1].strip()\n",
    "        else:\n",
    "            answer = answer.strip()\n",
    "\n",
    "        print(f\"Resposta gerada para a imagem {i}: {answer}\")\n",
    "        answers.append(answer)\n",
    "\n",
    "        del inputs\n",
    "        del output  \n",
    "        gc.collect() \n",
    "        \n",
    "        if model.device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Resposta gerada para {i} imagens.\")\n",
    "\n",
    "    return answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "700a9664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers_text_only(text_col: str, df: pd.DataFrame, model):\n",
    "\n",
    "    answers = []\n",
    "    model_df = df.copy()\n",
    "\n",
    "    for i in model_df.index:\n",
    "        image_infos = model_df.iloc[i]\n",
    "        image_description = image_infos[text_col]\n",
    "        image_question = image_infos['question']\n",
    "\n",
    "        prompt_formatado = PROMPT_SANITY_CHECK.format(text=image_description, question=image_question)\n",
    "   \n",
    "        inputs = processor(\n",
    "            text=prompt_formatado,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "\n",
    "        output = model.generate(**inputs, max_new_tokens=64, pad_token_id=processor.tokenizer.eos_token_id)\n",
    "        answer = processor.decode(output[0], skip_special_tokens=True).replace(prompt_formatado, \"\").strip()\n",
    "        answers.append(answer)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Resposta gerada para {i} imagens.\")\n",
    "\n",
    "    return answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c9e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers_mix(text_col: str, df: pd.DataFrame, model):\n",
    "\n",
    "    answers = []\n",
    "    model_df = df.copy()\n",
    "    base_image_path = 'images/'\n",
    "\n",
    "    for i in model_df.index:\n",
    "        image_infos = model_df.iloc[i]\n",
    "        image_description = image_infos[text_col]\n",
    "        image_question = image_infos['question']\n",
    "        image_path = base_image_path + image_infos['image_path']\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        prompt_formatado = PROMPT_MIX_RESPONSE.format(text_information=image_description, question=image_question)\n",
    "        prompt_formatado = f\"[INST] <image>\\n{prompt_formatado} [/INST]\"\n",
    "\n",
    "        inputs = processor(\n",
    "            text=prompt_formatado,\n",
    "            images=image,\n",
    "            return_tensors=\"pt\",\n",
    "            # padding=True\n",
    "        ).to(model.device)\n",
    "\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=100,\n",
    "            pad_token_id=processor.tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        answer = processor.decode(\n",
    "            output[0],\n",
    "            skip_special_tokens=True,\n",
    "        ).replace(image_question, \"\").strip()\n",
    "\n",
    "        if \"[/INST]\" in answer:\n",
    "            answer = answer.split(\"[/INST]\")[-1].strip()\n",
    "        else:\n",
    "            answer = answer.strip()\n",
    "\n",
    "        print(f\"Resposta gerada para a imagem {i}: {answer}\")\n",
    "        answers.append(answer)\n",
    "\n",
    "        del inputs\n",
    "        del output  \n",
    "        gc.collect() \n",
    "        \n",
    "        if model.device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Resposta gerada para {i} imagens.\")\n",
    "\n",
    "    return answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eba65b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/final_data_descriptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe286f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Ans</th>\n",
       "      <th>Ti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COCO_val2014_000000000042.jpg</td>\n",
       "      <td>42</td>\n",
       "      <td>What color are the gym shoes?</td>\n",
       "      <td>white</td>\n",
       "      <td>A curly-haired dog is sleeping on a shoe rack ...</td>\n",
       "      <td>A curly-haired dog is sleeping on a shoe rack ...</td>\n",
       "      <td>red</td>\n",
       "      <td>Several days after the low dissipated , the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>COCO_val2014_000000000073.jpg</td>\n",
       "      <td>73</td>\n",
       "      <td>What is the license number?</td>\n",
       "      <td>sv-6260</td>\n",
       "      <td>The motorcycle in the image has a license plat...</td>\n",
       "      <td>The motorcycle in the image has a license plat...</td>\n",
       "      <td>red</td>\n",
       "      <td>Kawaguchi 's Center Body of troops was planni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>COCO_val2014_000000000074.jpg</td>\n",
       "      <td>74</td>\n",
       "      <td>Does this dog have a collar?</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a white dog sleeping on a cobb...</td>\n",
       "      <td>The image shows a white dog sleeping on a cobb...</td>\n",
       "      <td>red</td>\n",
       "      <td>In the centre , the main attack along the Bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>COCO_val2014_000000000133.jpg</td>\n",
       "      <td>133</td>\n",
       "      <td>What color is lamp?</td>\n",
       "      <td>blue</td>\n",
       "      <td>The image shows a wooden loft bed with a small...</td>\n",
       "      <td>The image shows a wooden loft bed with a small...</td>\n",
       "      <td>red</td>\n",
       "      <td>Mount Elbert was named by miners in honor of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>COCO_val2014_000000000136.jpg</td>\n",
       "      <td>136</td>\n",
       "      <td>Is this in a museum?</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows two giraffes in an indoor zoo ...</td>\n",
       "      <td>The image shows two giraffes in a natural sava...</td>\n",
       "      <td>red</td>\n",
       "      <td>Runs west through Jackson , Mississippi , eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>991</td>\n",
       "      <td>991</td>\n",
       "      <td>COCO_val2014_000000014135.jpg</td>\n",
       "      <td>14135</td>\n",
       "      <td>Is it daytime?</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a skateboarder performing a tr...</td>\n",
       "      <td>The image shows a skateboarder performing a tr...</td>\n",
       "      <td>no</td>\n",
       "      <td>The documentary film Tim Richmond : To The Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>992</td>\n",
       "      <td>992</td>\n",
       "      <td>COCO_val2014_000000014151.jpg</td>\n",
       "      <td>14151</td>\n",
       "      <td>Is this at the Olympics?</td>\n",
       "      <td>yes</td>\n",
       "      <td>A ski jumper is in mid-air above a snow-covere...</td>\n",
       "      <td>A ski jumper is in mid-air above a snow-covere...</td>\n",
       "      <td>No, this is not at the Olympics.</td>\n",
       "      <td>Kevin Spacey as David &lt;unk&gt; \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>993</td>\n",
       "      <td>993</td>\n",
       "      <td>COCO_val2014_000000014167.jpg</td>\n",
       "      <td>14167</td>\n",
       "      <td>Is the skateboarder wearing safety gear?</td>\n",
       "      <td>no</td>\n",
       "      <td>The skateboarder is performing a trick down a ...</td>\n",
       "      <td>The skateboarder is performing a trick down a ...</td>\n",
       "      <td>blue</td>\n",
       "      <td>The Island Def Jam rapper Big K.R.I.T. was bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>994</td>\n",
       "      <td>994</td>\n",
       "      <td>COCO_val2014_000000014175.jpg</td>\n",
       "      <td>14175</td>\n",
       "      <td>What is sticking up from the fire hydrant?</td>\n",
       "      <td>nothing</td>\n",
       "      <td>The image shows a street scene with a fire hyd...</td>\n",
       "      <td>The image shows a street scene with a fire hyd...</td>\n",
       "      <td>red</td>\n",
       "      <td>A total of 2 @,@ 000 people attended Slammive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>COCO_val2014_000000014226.jpg</td>\n",
       "      <td>14226</td>\n",
       "      <td>What color is the boys jacket?</td>\n",
       "      <td>green</td>\n",
       "      <td>The boy is sitting on a train, wearing a blue ...</td>\n",
       "      <td>The boy is sitting on a train, wearing a red j...</td>\n",
       "      <td>red</td>\n",
       "      <td>Erik Wiese , a member of the SpongeBob Square...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1  Unnamed: 0                     image_path  image_id  \\\n",
       "0               0           0  COCO_val2014_000000000042.jpg        42   \n",
       "1               1           1  COCO_val2014_000000000073.jpg        73   \n",
       "2               2           2  COCO_val2014_000000000074.jpg        74   \n",
       "3               3           3  COCO_val2014_000000000133.jpg       133   \n",
       "4               4           4  COCO_val2014_000000000136.jpg       136   \n",
       "..            ...         ...                            ...       ...   \n",
       "991           991         991  COCO_val2014_000000014135.jpg     14135   \n",
       "992           992         992  COCO_val2014_000000014151.jpg     14151   \n",
       "993           993         993  COCO_val2014_000000014167.jpg     14167   \n",
       "994           994         994  COCO_val2014_000000014175.jpg     14175   \n",
       "995           995         995  COCO_val2014_000000014226.jpg     14226   \n",
       "\n",
       "                                       question   answer  \\\n",
       "0                 What color are the gym shoes?    white   \n",
       "1                   What is the license number?  sv-6260   \n",
       "2                  Does this dog have a collar?       no   \n",
       "3                           What color is lamp?     blue   \n",
       "4                          Is this in a museum?       no   \n",
       "..                                          ...      ...   \n",
       "991                              Is it daytime?      yes   \n",
       "992                    Is this at the Olympics?      yes   \n",
       "993    Is the skateboarder wearing safety gear?       no   \n",
       "994  What is sticking up from the fire hydrant?  nothing   \n",
       "995              What color is the boys jacket?    green   \n",
       "\n",
       "                                                    Tm  \\\n",
       "0    A curly-haired dog is sleeping on a shoe rack ...   \n",
       "1    The motorcycle in the image has a license plat...   \n",
       "2    The image shows a white dog sleeping on a cobb...   \n",
       "3    The image shows a wooden loft bed with a small...   \n",
       "4    The image shows two giraffes in an indoor zoo ...   \n",
       "..                                                 ...   \n",
       "991  The image shows a skateboarder performing a tr...   \n",
       "992  A ski jumper is in mid-air above a snow-covere...   \n",
       "993  The skateboarder is performing a trick down a ...   \n",
       "994  The image shows a street scene with a fire hyd...   \n",
       "995  The boy is sitting on a train, wearing a blue ...   \n",
       "\n",
       "                                                    Tc  \\\n",
       "0    A curly-haired dog is sleeping on a shoe rack ...   \n",
       "1    The motorcycle in the image has a license plat...   \n",
       "2    The image shows a white dog sleeping on a cobb...   \n",
       "3    The image shows a wooden loft bed with a small...   \n",
       "4    The image shows two giraffes in a natural sava...   \n",
       "..                                                 ...   \n",
       "991  The image shows a skateboarder performing a tr...   \n",
       "992  A ski jumper is in mid-air above a snow-covere...   \n",
       "993  The skateboarder is performing a trick down a ...   \n",
       "994  The image shows a street scene with a fire hyd...   \n",
       "995  The boy is sitting on a train, wearing a red j...   \n",
       "\n",
       "                                  Ans  \\\n",
       "0                                 red   \n",
       "1                                 red   \n",
       "2                                 red   \n",
       "3                                 red   \n",
       "4                                 red   \n",
       "..                                ...   \n",
       "991                                no   \n",
       "992  No, this is not at the Olympics.   \n",
       "993                              blue   \n",
       "994                               red   \n",
       "995                               red   \n",
       "\n",
       "                                                    Ti  \n",
       "0     Several days after the low dissipated , the r...  \n",
       "1     Kawaguchi 's Center Body of troops was planni...  \n",
       "2     In the centre , the main attack along the Bui...  \n",
       "3     Mount Elbert was named by miners in honor of ...  \n",
       "4     Runs west through Jackson , Mississippi , eve...  \n",
       "..                                                 ...  \n",
       "991   The documentary film Tim Richmond : To The Li...  \n",
       "992                     Kevin Spacey as David <unk> \\n  \n",
       "993   The Island Def Jam rapper Big K.R.I.T. was bo...  \n",
       "994   A total of 2 @,@ 000 people attended Slammive...  \n",
       "995   Erik Wiese , a member of the SpongeBob Square...  \n",
       "\n",
       "[996 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ef977ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "llava_df = df[['image_path', 'question', 'answer', 'Tm', 'Tc', 'Ti']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0846c640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Ti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCO_val2014_000000000042.jpg</td>\n",
       "      <td>What color are the gym shoes?</td>\n",
       "      <td>white</td>\n",
       "      <td>A curly-haired dog is sleeping on a shoe rack ...</td>\n",
       "      <td>A curly-haired dog is sleeping on a shoe rack ...</td>\n",
       "      <td>Several days after the low dissipated , the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COCO_val2014_000000000073.jpg</td>\n",
       "      <td>What is the license number?</td>\n",
       "      <td>sv-6260</td>\n",
       "      <td>The motorcycle in the image has a license plat...</td>\n",
       "      <td>The motorcycle in the image has a license plat...</td>\n",
       "      <td>Kawaguchi 's Center Body of troops was planni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COCO_val2014_000000000074.jpg</td>\n",
       "      <td>Does this dog have a collar?</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a white dog sleeping on a cobb...</td>\n",
       "      <td>The image shows a white dog sleeping on a cobb...</td>\n",
       "      <td>In the centre , the main attack along the Bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COCO_val2014_000000000133.jpg</td>\n",
       "      <td>What color is lamp?</td>\n",
       "      <td>blue</td>\n",
       "      <td>The image shows a wooden loft bed with a small...</td>\n",
       "      <td>The image shows a wooden loft bed with a small...</td>\n",
       "      <td>Mount Elbert was named by miners in honor of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COCO_val2014_000000000136.jpg</td>\n",
       "      <td>Is this in a museum?</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows two giraffes in an indoor zoo ...</td>\n",
       "      <td>The image shows two giraffes in a natural sava...</td>\n",
       "      <td>Runs west through Jackson , Mississippi , eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>COCO_val2014_000000014135.jpg</td>\n",
       "      <td>Is it daytime?</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a skateboarder performing a tr...</td>\n",
       "      <td>The image shows a skateboarder performing a tr...</td>\n",
       "      <td>The documentary film Tim Richmond : To The Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>COCO_val2014_000000014151.jpg</td>\n",
       "      <td>Is this at the Olympics?</td>\n",
       "      <td>yes</td>\n",
       "      <td>A ski jumper is in mid-air above a snow-covere...</td>\n",
       "      <td>A ski jumper is in mid-air above a snow-covere...</td>\n",
       "      <td>Kevin Spacey as David &lt;unk&gt; \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>COCO_val2014_000000014167.jpg</td>\n",
       "      <td>Is the skateboarder wearing safety gear?</td>\n",
       "      <td>no</td>\n",
       "      <td>The skateboarder is performing a trick down a ...</td>\n",
       "      <td>The skateboarder is performing a trick down a ...</td>\n",
       "      <td>The Island Def Jam rapper Big K.R.I.T. was bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>COCO_val2014_000000014175.jpg</td>\n",
       "      <td>What is sticking up from the fire hydrant?</td>\n",
       "      <td>nothing</td>\n",
       "      <td>The image shows a street scene with a fire hyd...</td>\n",
       "      <td>The image shows a street scene with a fire hyd...</td>\n",
       "      <td>A total of 2 @,@ 000 people attended Slammive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>COCO_val2014_000000014226.jpg</td>\n",
       "      <td>What color is the boys jacket?</td>\n",
       "      <td>green</td>\n",
       "      <td>The boy is sitting on a train, wearing a blue ...</td>\n",
       "      <td>The boy is sitting on a train, wearing a red j...</td>\n",
       "      <td>Erik Wiese , a member of the SpongeBob Square...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        image_path  \\\n",
       "0    COCO_val2014_000000000042.jpg   \n",
       "1    COCO_val2014_000000000073.jpg   \n",
       "2    COCO_val2014_000000000074.jpg   \n",
       "3    COCO_val2014_000000000133.jpg   \n",
       "4    COCO_val2014_000000000136.jpg   \n",
       "..                             ...   \n",
       "991  COCO_val2014_000000014135.jpg   \n",
       "992  COCO_val2014_000000014151.jpg   \n",
       "993  COCO_val2014_000000014167.jpg   \n",
       "994  COCO_val2014_000000014175.jpg   \n",
       "995  COCO_val2014_000000014226.jpg   \n",
       "\n",
       "                                       question   answer  \\\n",
       "0                 What color are the gym shoes?    white   \n",
       "1                   What is the license number?  sv-6260   \n",
       "2                  Does this dog have a collar?       no   \n",
       "3                           What color is lamp?     blue   \n",
       "4                          Is this in a museum?       no   \n",
       "..                                          ...      ...   \n",
       "991                              Is it daytime?      yes   \n",
       "992                    Is this at the Olympics?      yes   \n",
       "993    Is the skateboarder wearing safety gear?       no   \n",
       "994  What is sticking up from the fire hydrant?  nothing   \n",
       "995              What color is the boys jacket?    green   \n",
       "\n",
       "                                                    Tm  \\\n",
       "0    A curly-haired dog is sleeping on a shoe rack ...   \n",
       "1    The motorcycle in the image has a license plat...   \n",
       "2    The image shows a white dog sleeping on a cobb...   \n",
       "3    The image shows a wooden loft bed with a small...   \n",
       "4    The image shows two giraffes in an indoor zoo ...   \n",
       "..                                                 ...   \n",
       "991  The image shows a skateboarder performing a tr...   \n",
       "992  A ski jumper is in mid-air above a snow-covere...   \n",
       "993  The skateboarder is performing a trick down a ...   \n",
       "994  The image shows a street scene with a fire hyd...   \n",
       "995  The boy is sitting on a train, wearing a blue ...   \n",
       "\n",
       "                                                    Tc  \\\n",
       "0    A curly-haired dog is sleeping on a shoe rack ...   \n",
       "1    The motorcycle in the image has a license plat...   \n",
       "2    The image shows a white dog sleeping on a cobb...   \n",
       "3    The image shows a wooden loft bed with a small...   \n",
       "4    The image shows two giraffes in a natural sava...   \n",
       "..                                                 ...   \n",
       "991  The image shows a skateboarder performing a tr...   \n",
       "992  A ski jumper is in mid-air above a snow-covere...   \n",
       "993  The skateboarder is performing a trick down a ...   \n",
       "994  The image shows a street scene with a fire hyd...   \n",
       "995  The boy is sitting on a train, wearing a red j...   \n",
       "\n",
       "                                                    Ti  \n",
       "0     Several days after the low dissipated , the r...  \n",
       "1     Kawaguchi 's Center Body of troops was planni...  \n",
       "2     In the centre , the main attack along the Bui...  \n",
       "3     Mount Elbert was named by miners in honor of ...  \n",
       "4     Runs west through Jackson , Mississippi , eve...  \n",
       "..                                                 ...  \n",
       "991   The documentary film Tim Richmond : To The Li...  \n",
       "992                     Kevin Spacey as David <unk> \\n  \n",
       "993   The Island Def Jam rapper Big K.R.I.T. was bo...  \n",
       "994   A total of 2 @,@ 000 people attended Slammive...  \n",
       "995   Erik Wiese , a member of the SpongeBob Square...  \n",
       "\n",
       "[996 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llava_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f856a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llava_tm_responses = generate_answers_text_only('Tm', llava_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a920afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta gerada para 0 imagens.\n",
      "Resposta gerada para 100 imagens.\n",
      "Resposta gerada para 200 imagens.\n",
      "Resposta gerada para 300 imagens.\n",
      "Resposta gerada para 400 imagens.\n",
      "Resposta gerada para 500 imagens.\n",
      "Resposta gerada para 600 imagens.\n",
      "Resposta gerada para 700 imagens.\n",
      "Resposta gerada para 800 imagens.\n",
      "Resposta gerada para 900 imagens.\n"
     ]
    }
   ],
   "source": [
    "llava_ti_responses = generate_answers_text_only('Ti', llava_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09b590ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta gerada para 0 imagens.\n",
      "Resposta gerada para 100 imagens.\n",
      "Resposta gerada para 200 imagens.\n",
      "Resposta gerada para 300 imagens.\n",
      "Resposta gerada para 400 imagens.\n",
      "Resposta gerada para 500 imagens.\n",
      "Resposta gerada para 600 imagens.\n",
      "Resposta gerada para 700 imagens.\n",
      "Resposta gerada para 800 imagens.\n",
      "Resposta gerada para 900 imagens.\n"
     ]
    }
   ],
   "source": [
    "llava_tc_responses = generate_answers_text_only('Tc', llava_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0cc6abbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8528\\1353033619.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  llava_df['Tc_responses'] = pd.Series(llava_tc_responses)\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8528\\1353033619.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  llava_df['Tm_responses'] = pd.Series(llava_tm_responses)\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8528\\1353033619.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  llava_df['Ti_responses'] = pd.Series(llava_ti_responses)\n"
     ]
    }
   ],
   "source": [
    "llava_df['Tc_responses'] = pd.Series(llava_tc_responses)\n",
    "llava_df['Tm_responses'] = pd.Series(llava_tm_responses)\n",
    "llava_df['Ti_responses'] = pd.Series(llava_ti_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ccc11f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Ti</th>\n",
       "      <th>Tc_responses</th>\n",
       "      <th>Tm_responses</th>\n",
       "      <th>Ti_responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCO_val2014_000000000042.jpg</td>\n",
       "      <td>What color are the gym shoes?</td>\n",
       "      <td>white</td>\n",
       "      <td>A curly-haired dog is sleeping on a shoe rack ...</td>\n",
       "      <td>A curly-haired dog is sleeping on a shoe rack ...</td>\n",
       "      <td>Several days after the low dissipated , the r...</td>\n",
       "      <td>Red</td>\n",
       "      <td>Blue</td>\n",
       "      <td>No gym shoes in the text.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COCO_val2014_000000000073.jpg</td>\n",
       "      <td>What is the license number?</td>\n",
       "      <td>sv-6260</td>\n",
       "      <td>The motorcycle in the image has a license plat...</td>\n",
       "      <td>The motorcycle in the image has a license plat...</td>\n",
       "      <td>Kawaguchi 's Center Body of troops was planni...</td>\n",
       "      <td>AB-1234</td>\n",
       "      <td>SV-6260</td>\n",
       "      <td>Answer the following question given the text:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COCO_val2014_000000000074.jpg</td>\n",
       "      <td>Does this dog have a collar?</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a white dog sleeping on a cobb...</td>\n",
       "      <td>The image shows a white dog sleeping on a cobb...</td>\n",
       "      <td>In the centre , the main attack along the Bui...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Answer the following question given the text:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COCO_val2014_000000000133.jpg</td>\n",
       "      <td>What color is lamp?</td>\n",
       "      <td>blue</td>\n",
       "      <td>The image shows a wooden loft bed with a small...</td>\n",
       "      <td>The image shows a wooden loft bed with a small...</td>\n",
       "      <td>Mount Elbert was named by miners in honor of ...</td>\n",
       "      <td>Red</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Answer the following question given the text:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COCO_val2014_000000000136.jpg</td>\n",
       "      <td>Is this in a museum?</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows two giraffes in an indoor zoo ...</td>\n",
       "      <td>The image shows two giraffes in a natural sava...</td>\n",
       "      <td>Runs west through Jackson , Mississippi , eve...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>COCO_val2014_000000014135.jpg</td>\n",
       "      <td>Is it daytime?</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a skateboarder performing a tr...</td>\n",
       "      <td>The image shows a skateboarder performing a tr...</td>\n",
       "      <td>The documentary film Tim Richmond : To The Li...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>COCO_val2014_000000014151.jpg</td>\n",
       "      <td>Is this at the Olympics?</td>\n",
       "      <td>yes</td>\n",
       "      <td>A ski jumper is in mid-air above a snow-covere...</td>\n",
       "      <td>A ski jumper is in mid-air above a snow-covere...</td>\n",
       "      <td>Kevin Spacey as David &lt;unk&gt; \\n</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Answer the following question given the text:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>COCO_val2014_000000014167.jpg</td>\n",
       "      <td>Is the skateboarder wearing safety gear?</td>\n",
       "      <td>no</td>\n",
       "      <td>The skateboarder is performing a trick down a ...</td>\n",
       "      <td>The skateboarder is performing a trick down a ...</td>\n",
       "      <td>The Island Def Jam rapper Big K.R.I.T. was bo...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Answer the following question given the text:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>COCO_val2014_000000014175.jpg</td>\n",
       "      <td>What is sticking up from the fire hydrant?</td>\n",
       "      <td>nothing</td>\n",
       "      <td>The image shows a street scene with a fire hyd...</td>\n",
       "      <td>The image shows a street scene with a fire hyd...</td>\n",
       "      <td>A total of 2 @,@ 000 people attended Slammive...</td>\n",
       "      <td>Red object</td>\n",
       "      <td>Blue object</td>\n",
       "      <td>No fire hydrant in the text.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>COCO_val2014_000000014226.jpg</td>\n",
       "      <td>What color is the boys jacket?</td>\n",
       "      <td>green</td>\n",
       "      <td>The boy is sitting on a train, wearing a blue ...</td>\n",
       "      <td>The boy is sitting on a train, wearing a red j...</td>\n",
       "      <td>Erik Wiese , a member of the SpongeBob Square...</td>\n",
       "      <td>Red</td>\n",
       "      <td>Blue</td>\n",
       "      <td>No boys jacket in the text.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        image_path  \\\n",
       "0    COCO_val2014_000000000042.jpg   \n",
       "1    COCO_val2014_000000000073.jpg   \n",
       "2    COCO_val2014_000000000074.jpg   \n",
       "3    COCO_val2014_000000000133.jpg   \n",
       "4    COCO_val2014_000000000136.jpg   \n",
       "..                             ...   \n",
       "991  COCO_val2014_000000014135.jpg   \n",
       "992  COCO_val2014_000000014151.jpg   \n",
       "993  COCO_val2014_000000014167.jpg   \n",
       "994  COCO_val2014_000000014175.jpg   \n",
       "995  COCO_val2014_000000014226.jpg   \n",
       "\n",
       "                                       question   answer  \\\n",
       "0                 What color are the gym shoes?    white   \n",
       "1                   What is the license number?  sv-6260   \n",
       "2                  Does this dog have a collar?       no   \n",
       "3                           What color is lamp?     blue   \n",
       "4                          Is this in a museum?       no   \n",
       "..                                          ...      ...   \n",
       "991                              Is it daytime?      yes   \n",
       "992                    Is this at the Olympics?      yes   \n",
       "993    Is the skateboarder wearing safety gear?       no   \n",
       "994  What is sticking up from the fire hydrant?  nothing   \n",
       "995              What color is the boys jacket?    green   \n",
       "\n",
       "                                                    Tm  \\\n",
       "0    A curly-haired dog is sleeping on a shoe rack ...   \n",
       "1    The motorcycle in the image has a license plat...   \n",
       "2    The image shows a white dog sleeping on a cobb...   \n",
       "3    The image shows a wooden loft bed with a small...   \n",
       "4    The image shows two giraffes in an indoor zoo ...   \n",
       "..                                                 ...   \n",
       "991  The image shows a skateboarder performing a tr...   \n",
       "992  A ski jumper is in mid-air above a snow-covere...   \n",
       "993  The skateboarder is performing a trick down a ...   \n",
       "994  The image shows a street scene with a fire hyd...   \n",
       "995  The boy is sitting on a train, wearing a blue ...   \n",
       "\n",
       "                                                    Tc  \\\n",
       "0    A curly-haired dog is sleeping on a shoe rack ...   \n",
       "1    The motorcycle in the image has a license plat...   \n",
       "2    The image shows a white dog sleeping on a cobb...   \n",
       "3    The image shows a wooden loft bed with a small...   \n",
       "4    The image shows two giraffes in a natural sava...   \n",
       "..                                                 ...   \n",
       "991  The image shows a skateboarder performing a tr...   \n",
       "992  A ski jumper is in mid-air above a snow-covere...   \n",
       "993  The skateboarder is performing a trick down a ...   \n",
       "994  The image shows a street scene with a fire hyd...   \n",
       "995  The boy is sitting on a train, wearing a red j...   \n",
       "\n",
       "                                                    Ti Tc_responses  \\\n",
       "0     Several days after the low dissipated , the r...          Red   \n",
       "1     Kawaguchi 's Center Body of troops was planni...      AB-1234   \n",
       "2     In the centre , the main attack along the Bui...          Yes   \n",
       "3     Mount Elbert was named by miners in honor of ...          Red   \n",
       "4     Runs west through Jackson , Mississippi , eve...           No   \n",
       "..                                                 ...          ...   \n",
       "991   The documentary film Tim Richmond : To The Li...           No   \n",
       "992                     Kevin Spacey as David <unk> \\n           No   \n",
       "993   The Island Def Jam rapper Big K.R.I.T. was bo...          Yes   \n",
       "994   A total of 2 @,@ 000 people attended Slammive...   Red object   \n",
       "995   Erik Wiese , a member of the SpongeBob Square...          Red   \n",
       "\n",
       "    Tm_responses                                       Ti_responses  \n",
       "0           Blue                          No gym shoes in the text.  \n",
       "1        SV-6260  Answer the following question given the text:\\...  \n",
       "2            Yes  Answer the following question given the text:\\...  \n",
       "3           Blue  Answer the following question given the text:\\...  \n",
       "4             No                                                 No  \n",
       "..           ...                                                ...  \n",
       "991          Yes                                                Yes  \n",
       "992          Yes  Answer the following question given the text:\\...  \n",
       "993           No  Answer the following question given the text:\\...  \n",
       "994  Blue object                       No fire hydrant in the text.  \n",
       "995         Blue                        No boys jacket in the text.  \n",
       "\n",
       "[996 rows x 9 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llava_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c5638be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ti responses ficou poluido com prompt em alguns casos. Tratando isso\n",
    "cleaned_llava_ti_responses = []\n",
    "\n",
    "for ti in llava_ti_responses:\n",
    "\n",
    "    if 'full sentences' in ti:\n",
    "        t = ti.split('full sentences')[-1].replace('\\n','').replace('.','')\n",
    "        cleaned_llava_ti_responses.append(t)\n",
    "    else:\n",
    "        cleaned_llava_ti_responses.append(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2862c0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8528\\1326183197.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  llava_df['Ti_responses'] = pd.Series(cleaned_llava_ti_responses)\n"
     ]
    }
   ],
   "source": [
    "llava_df['Ti_responses'] = pd.Series(cleaned_llava_ti_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "633bda76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Ti</th>\n",
       "      <th>Tc_responses</th>\n",
       "      <th>Tm_responses</th>\n",
       "      <th>Ti_responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCO_val2014_000000000042.jpg</td>\n",
       "      <td>What color are the gym shoes?</td>\n",
       "      <td>white</td>\n",
       "      <td>A curly-haired dog is sleeping on a shoe rack ...</td>\n",
       "      <td>A curly-haired dog is sleeping on a shoe rack ...</td>\n",
       "      <td>Several days after the low dissipated , the r...</td>\n",
       "      <td>Red</td>\n",
       "      <td>Blue</td>\n",
       "      <td>No gym shoes in the text.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COCO_val2014_000000000073.jpg</td>\n",
       "      <td>What is the license number?</td>\n",
       "      <td>sv-6260</td>\n",
       "      <td>The motorcycle in the image has a license plat...</td>\n",
       "      <td>The motorcycle in the image has a license plat...</td>\n",
       "      <td>Kawaguchi 's Center Body of troops was planni...</td>\n",
       "      <td>AB-1234</td>\n",
       "      <td>SV-6260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COCO_val2014_000000000074.jpg</td>\n",
       "      <td>Does this dog have a collar?</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a white dog sleeping on a cobb...</td>\n",
       "      <td>The image shows a white dog sleeping on a cobb...</td>\n",
       "      <td>In the centre , the main attack along the Bui...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COCO_val2014_000000000133.jpg</td>\n",
       "      <td>What color is lamp?</td>\n",
       "      <td>blue</td>\n",
       "      <td>The image shows a wooden loft bed with a small...</td>\n",
       "      <td>The image shows a wooden loft bed with a small...</td>\n",
       "      <td>Mount Elbert was named by miners in honor of ...</td>\n",
       "      <td>Red</td>\n",
       "      <td>Blue</td>\n",
       "      <td>No lamp in the text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COCO_val2014_000000000136.jpg</td>\n",
       "      <td>Is this in a museum?</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows two giraffes in an indoor zoo ...</td>\n",
       "      <td>The image shows two giraffes in a natural sava...</td>\n",
       "      <td>Runs west through Jackson , Mississippi , eve...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>COCO_val2014_000000014135.jpg</td>\n",
       "      <td>Is it daytime?</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a skateboarder performing a tr...</td>\n",
       "      <td>The image shows a skateboarder performing a tr...</td>\n",
       "      <td>The documentary film Tim Richmond : To The Li...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>COCO_val2014_000000014151.jpg</td>\n",
       "      <td>Is this at the Olympics?</td>\n",
       "      <td>yes</td>\n",
       "      <td>A ski jumper is in mid-air above a snow-covere...</td>\n",
       "      <td>A ski jumper is in mid-air above a snow-covere...</td>\n",
       "      <td>Kevin Spacey as David &lt;unk&gt; \\n</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>COCO_val2014_000000014167.jpg</td>\n",
       "      <td>Is the skateboarder wearing safety gear?</td>\n",
       "      <td>no</td>\n",
       "      <td>The skateboarder is performing a trick down a ...</td>\n",
       "      <td>The skateboarder is performing a trick down a ...</td>\n",
       "      <td>The Island Def Jam rapper Big K.R.I.T. was bo...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>COCO_val2014_000000014175.jpg</td>\n",
       "      <td>What is sticking up from the fire hydrant?</td>\n",
       "      <td>nothing</td>\n",
       "      <td>The image shows a street scene with a fire hyd...</td>\n",
       "      <td>The image shows a street scene with a fire hyd...</td>\n",
       "      <td>A total of 2 @,@ 000 people attended Slammive...</td>\n",
       "      <td>Red object</td>\n",
       "      <td>Blue object</td>\n",
       "      <td>No fire hydrant in the text.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>COCO_val2014_000000014226.jpg</td>\n",
       "      <td>What color is the boys jacket?</td>\n",
       "      <td>green</td>\n",
       "      <td>The boy is sitting on a train, wearing a blue ...</td>\n",
       "      <td>The boy is sitting on a train, wearing a red j...</td>\n",
       "      <td>Erik Wiese , a member of the SpongeBob Square...</td>\n",
       "      <td>Red</td>\n",
       "      <td>Blue</td>\n",
       "      <td>No boys jacket in the text.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        image_path  \\\n",
       "0    COCO_val2014_000000000042.jpg   \n",
       "1    COCO_val2014_000000000073.jpg   \n",
       "2    COCO_val2014_000000000074.jpg   \n",
       "3    COCO_val2014_000000000133.jpg   \n",
       "4    COCO_val2014_000000000136.jpg   \n",
       "..                             ...   \n",
       "991  COCO_val2014_000000014135.jpg   \n",
       "992  COCO_val2014_000000014151.jpg   \n",
       "993  COCO_val2014_000000014167.jpg   \n",
       "994  COCO_val2014_000000014175.jpg   \n",
       "995  COCO_val2014_000000014226.jpg   \n",
       "\n",
       "                                       question   answer  \\\n",
       "0                 What color are the gym shoes?    white   \n",
       "1                   What is the license number?  sv-6260   \n",
       "2                  Does this dog have a collar?       no   \n",
       "3                           What color is lamp?     blue   \n",
       "4                          Is this in a museum?       no   \n",
       "..                                          ...      ...   \n",
       "991                              Is it daytime?      yes   \n",
       "992                    Is this at the Olympics?      yes   \n",
       "993    Is the skateboarder wearing safety gear?       no   \n",
       "994  What is sticking up from the fire hydrant?  nothing   \n",
       "995              What color is the boys jacket?    green   \n",
       "\n",
       "                                                    Tm  \\\n",
       "0    A curly-haired dog is sleeping on a shoe rack ...   \n",
       "1    The motorcycle in the image has a license plat...   \n",
       "2    The image shows a white dog sleeping on a cobb...   \n",
       "3    The image shows a wooden loft bed with a small...   \n",
       "4    The image shows two giraffes in an indoor zoo ...   \n",
       "..                                                 ...   \n",
       "991  The image shows a skateboarder performing a tr...   \n",
       "992  A ski jumper is in mid-air above a snow-covere...   \n",
       "993  The skateboarder is performing a trick down a ...   \n",
       "994  The image shows a street scene with a fire hyd...   \n",
       "995  The boy is sitting on a train, wearing a blue ...   \n",
       "\n",
       "                                                    Tc  \\\n",
       "0    A curly-haired dog is sleeping on a shoe rack ...   \n",
       "1    The motorcycle in the image has a license plat...   \n",
       "2    The image shows a white dog sleeping on a cobb...   \n",
       "3    The image shows a wooden loft bed with a small...   \n",
       "4    The image shows two giraffes in a natural sava...   \n",
       "..                                                 ...   \n",
       "991  The image shows a skateboarder performing a tr...   \n",
       "992  A ski jumper is in mid-air above a snow-covere...   \n",
       "993  The skateboarder is performing a trick down a ...   \n",
       "994  The image shows a street scene with a fire hyd...   \n",
       "995  The boy is sitting on a train, wearing a red j...   \n",
       "\n",
       "                                                    Ti Tc_responses  \\\n",
       "0     Several days after the low dissipated , the r...          Red   \n",
       "1     Kawaguchi 's Center Body of troops was planni...      AB-1234   \n",
       "2     In the centre , the main attack along the Bui...          Yes   \n",
       "3     Mount Elbert was named by miners in honor of ...          Red   \n",
       "4     Runs west through Jackson , Mississippi , eve...           No   \n",
       "..                                                 ...          ...   \n",
       "991   The documentary film Tim Richmond : To The Li...           No   \n",
       "992                     Kevin Spacey as David <unk> \\n           No   \n",
       "993   The Island Def Jam rapper Big K.R.I.T. was bo...          Yes   \n",
       "994   A total of 2 @,@ 000 people attended Slammive...   Red object   \n",
       "995   Erik Wiese , a member of the SpongeBob Square...          Red   \n",
       "\n",
       "    Tm_responses                  Ti_responses  \n",
       "0           Blue     No gym shoes in the text.  \n",
       "1        SV-6260                             0  \n",
       "2            Yes                            No  \n",
       "3           Blue           No lamp in the text  \n",
       "4             No                            No  \n",
       "..           ...                           ...  \n",
       "991          Yes                           Yes  \n",
       "992          Yes                            No  \n",
       "993           No                            No  \n",
       "994  Blue object  No fire hydrant in the text.  \n",
       "995         Blue   No boys jacket in the text.  \n",
       "\n",
       "[996 rows x 9 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llava_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b567576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecionando apenas 10 amostras pelo custo\n",
    "\n",
    "mini_llava_df = llava_df.sample(n=10, random_state=42)\n",
    "mini_llava_df = mini_llava_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f7c25ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Ti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCO_val2014_000000011703.jpg</td>\n",
       "      <td>Was this picture taken in front of a door way?</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows the interior of a train with a...</td>\n",
       "      <td>The image shows the interior of a train with a...</td>\n",
       "      <td>A Little Matter of Genocide . San Francisco C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COCO_val2014_000000013867.jpg</td>\n",
       "      <td>What object is the person carrying?</td>\n",
       "      <td>frisbee</td>\n",
       "      <td>The person is standing on a grassy field, wear...</td>\n",
       "      <td>The person is standing on a grassy field, wear...</td>\n",
       "      <td>Perhaps the most enduring legacy of the Mongo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COCO_val2014_000000001268.jpg</td>\n",
       "      <td>What color is the grass?</td>\n",
       "      <td>green</td>\n",
       "      <td>The image shows a scene under a bridge by a ri...</td>\n",
       "      <td>The image shows a scene under a bridge by a ri...</td>\n",
       "      <td>Adrien Begrand of PopMatters remarked that \" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COCO_val2014_000000008292.jpg</td>\n",
       "      <td>What room is this?</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>The image shows a narrow kitchen with a stove,...</td>\n",
       "      <td>The image shows a narrow bathroom with a batht...</td>\n",
       "      <td>McCarty grew up in Muskogee , Oklahoma . Afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COCO_val2014_000000006471.jpg</td>\n",
       "      <td>What do their shirts' say?</td>\n",
       "      <td>10</td>\n",
       "      <td>The players' shirts have the word \"Bowie\" writ...</td>\n",
       "      <td>The players' shirts have the word \"Blue\" writt...</td>\n",
       "      <td>The writer of the scenario is unknown , but i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COCO_val2014_000000003817.jpg</td>\n",
       "      <td>What is this man hauling?</td>\n",
       "      <td>bananas</td>\n",
       "      <td>A man is riding a motorcycle on a rural road, ...</td>\n",
       "      <td>A man is riding a motorcycle on a rural road, ...</td>\n",
       "      <td>In this episode , Federal Bureau of Investiga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCO_val2014_000000004134.jpg</td>\n",
       "      <td>What is the person on the left doing with thei...</td>\n",
       "      <td>shaking</td>\n",
       "      <td>The person on the left is shaking hands with t...</td>\n",
       "      <td>The person on the left is holding a glass of w...</td>\n",
       "      <td>NME lauded the song as the opening track by s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COCO_val2014_000000002061.jpg</td>\n",
       "      <td>Who is in the toilet?</td>\n",
       "      <td>no one</td>\n",
       "      <td>The toilet is empty, with a blue cleaning brus...</td>\n",
       "      <td>The toilet is occupied by a person wearing a b...</td>\n",
       "      <td>The video begins with an aerial shot of a blo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COCO_val2014_000000009448.jpg</td>\n",
       "      <td>Is this girl eating a cookie?</td>\n",
       "      <td>yes</td>\n",
       "      <td>The girl is holding a blue umbrella and appear...</td>\n",
       "      <td>The girl is holding a blue umbrella and appear...</td>\n",
       "      <td>With its sequels for the Genesis , Sonic the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COCO_val2014_000000008128.jpg</td>\n",
       "      <td>Is the sky dark and overcast?</td>\n",
       "      <td>no</td>\n",
       "      <td>The sky is clear and blue with some light clou...</td>\n",
       "      <td>The sky is dark and overcast with heavy clouds...</td>\n",
       "      <td>In a return match on 19 January , Yorkshire f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      image_path  \\\n",
       "0  COCO_val2014_000000011703.jpg   \n",
       "1  COCO_val2014_000000013867.jpg   \n",
       "2  COCO_val2014_000000001268.jpg   \n",
       "3  COCO_val2014_000000008292.jpg   \n",
       "4  COCO_val2014_000000006471.jpg   \n",
       "5  COCO_val2014_000000003817.jpg   \n",
       "6  COCO_val2014_000000004134.jpg   \n",
       "7  COCO_val2014_000000002061.jpg   \n",
       "8  COCO_val2014_000000009448.jpg   \n",
       "9  COCO_val2014_000000008128.jpg   \n",
       "\n",
       "                                            question   answer  \\\n",
       "0     Was this picture taken in front of a door way?      yes   \n",
       "1                What object is the person carrying?  frisbee   \n",
       "2                           What color is the grass?    green   \n",
       "3                                 What room is this?  kitchen   \n",
       "4                         What do their shirts' say?       10   \n",
       "5                          What is this man hauling?  bananas   \n",
       "6  What is the person on the left doing with thei...  shaking   \n",
       "7                              Who is in the toilet?   no one   \n",
       "8                      Is this girl eating a cookie?      yes   \n",
       "9                      Is the sky dark and overcast?       no   \n",
       "\n",
       "                                                  Tm  \\\n",
       "0  The image shows the interior of a train with a...   \n",
       "1  The person is standing on a grassy field, wear...   \n",
       "2  The image shows a scene under a bridge by a ri...   \n",
       "3  The image shows a narrow kitchen with a stove,...   \n",
       "4  The players' shirts have the word \"Bowie\" writ...   \n",
       "5  A man is riding a motorcycle on a rural road, ...   \n",
       "6  The person on the left is shaking hands with t...   \n",
       "7  The toilet is empty, with a blue cleaning brus...   \n",
       "8  The girl is holding a blue umbrella and appear...   \n",
       "9  The sky is clear and blue with some light clou...   \n",
       "\n",
       "                                                  Tc  \\\n",
       "0  The image shows the interior of a train with a...   \n",
       "1  The person is standing on a grassy field, wear...   \n",
       "2  The image shows a scene under a bridge by a ri...   \n",
       "3  The image shows a narrow bathroom with a batht...   \n",
       "4  The players' shirts have the word \"Blue\" writt...   \n",
       "5  A man is riding a motorcycle on a rural road, ...   \n",
       "6  The person on the left is holding a glass of w...   \n",
       "7  The toilet is occupied by a person wearing a b...   \n",
       "8  The girl is holding a blue umbrella and appear...   \n",
       "9  The sky is dark and overcast with heavy clouds...   \n",
       "\n",
       "                                                  Ti  \n",
       "0   A Little Matter of Genocide . San Francisco C...  \n",
       "1   Perhaps the most enduring legacy of the Mongo...  \n",
       "2   Adrien Begrand of PopMatters remarked that \" ...  \n",
       "3   McCarty grew up in Muskogee , Oklahoma . Afte...  \n",
       "4   The writer of the scenario is unknown , but i...  \n",
       "5   In this episode , Federal Bureau of Investiga...  \n",
       "6   NME lauded the song as the opening track by s...  \n",
       "7   The video begins with an aerial shot of a blo...  \n",
       "8   With its sequels for the Genesis , Sonic the ...  \n",
       "9   In a return match on 19 January , Yorkshire f...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_llava_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ec560c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m llava_base_response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_answers_image_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmini_llava_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m, in \u001b[0;36mgenerate_answers_image_only\u001b[1;34m(df, model)\u001b[0m\n\u001b[0;32m     12\u001b[0m prompt_text \u001b[38;5;241m=\u001b[39m image_question \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRespond only with the final answer, without explanation or full sentences.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m prompt_image_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INST] <image>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprompt_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [/INST]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_image_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# padding=True\u001b[39;49;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m     25\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     26\u001b[0m     pad_token_id\u001b[38;5;241m=\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     29\u001b[0m answer \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[0;32m     30\u001b[0m     output[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     31\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     32\u001b[0m )\u001b[38;5;241m.\u001b[39mreplace(image_question, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\transformers\\feature_extraction_utils.py:246\u001b[0m, in \u001b[0;36mBatchFeature.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m v\n\u001b[1;32m--> 246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: maybe_to(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\transformers\\feature_extraction_utils.py:246\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m v\n\u001b[1;32m--> 246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: \u001b[43mmaybe_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\transformers\\feature_extraction_utils.py:242\u001b[0m, in \u001b[0;36mBatchFeature.to.<locals>.maybe_to\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m v\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;129;01mand\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m v\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "llava_base_response = generate_answers_image_only(mini_llava_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75615d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "llava_mix_ti_responses = generate_answers_mix('Ti',mini_llava_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614cff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llava_mix_tc_responses = generate_answers_mix('Tc',mini_llava_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0c6a4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta gerada para a imagem 0: Yes\n",
      "Resposta gerada para 0 imagens.\n",
      "Resposta gerada para a imagem 1: Frisbee\n",
      "Resposta gerada para a imagem 2: Green\n",
      "Resposta gerada para a imagem 3: Kitchen\n",
      "Resposta gerada para a imagem 4: Bowie\n",
      "Resposta gerada para a imagem 5: Bananas\n",
      "Resposta gerada para a imagem 6: Shaking\n",
      "Resposta gerada para a imagem 7: No one\n",
      "Resposta gerada para a imagem 8: Yes\n",
      "Resposta gerada para a imagem 9: No\n",
      "Resposta gerada para a imagem 10: Green and white\n",
      "Resposta gerada para a imagem 11: Parked\n",
      "Resposta gerada para a imagem 12: Oven\n",
      "Resposta gerada para a imagem 13: No\n",
      "Resposta gerada para a imagem 14: Blue\n",
      "Resposta gerada para a imagem 15: 1.39\n",
      "Resposta gerada para a imagem 16: S\n",
      "Resposta gerada para a imagem 17: 4\n",
      "Resposta gerada para a imagem 18: No\n",
      "Resposta gerada para a imagem 19: No\n",
      "Resposta gerada para a imagem 20: Yes\n",
      "Resposta gerada para a imagem 21: No\n",
      "Resposta gerada para a imagem 22: Stripes\n",
      "Resposta gerada para a imagem 23: Yes\n",
      "Resposta gerada para a imagem 24: Sculpture\n",
      "Resposta gerada para a imagem 25: 1\n",
      "Resposta gerada para a imagem 26: Yes\n",
      "Resposta gerada para a imagem 27: Odd\n",
      "Resposta gerada para a imagem 28: Church\n",
      "Resposta gerada para a imagem 29: No\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m llava_mix_tm_responses \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_answers_mix\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmini_llava_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m, in \u001b[0;36mgenerate_answers_mix\u001b[1;34m(text_col, df, model)\u001b[0m\n\u001b[0;32m     15\u001b[0m prompt_formatado \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INST] <image>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprompt_formatado\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [/INST]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m inputs \u001b[38;5;241m=\u001b[39m processor(\n\u001b[0;32m     18\u001b[0m     text\u001b[38;5;241m=\u001b[39mprompt_formatado,\n\u001b[0;32m     19\u001b[0m     images\u001b[38;5;241m=\u001b[39mimage,\n\u001b[0;32m     20\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# padding=True\u001b[39;00m\n\u001b[0;32m     22\u001b[0m )\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m---> 24\u001b[0m output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m     26\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     27\u001b[0m     pad_token_id\u001b[38;5;241m=\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m answer \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[0;32m     31\u001b[0m     output[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     32\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     33\u001b[0m )\u001b[38;5;241m.\u001b[39mreplace(image_question, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[/INST]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m answer:\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\transformers\\generation\\utils.py:2564\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[0;32m   2561\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[0;32m   2563\u001b[0m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[1;32m-> 2564\u001b[0m result \u001b[38;5;241m=\u001b[39m decoding_method(\n\u001b[0;32m   2565\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2566\u001b[0m     input_ids,\n\u001b[0;32m   2567\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2568\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2569\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2570\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgeneration_mode_kwargs,\n\u001b[0;32m   2571\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2572\u001b[0m )\n\u001b[0;32m   2574\u001b[0m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[0;32m   2575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2576\u001b[0m     generation_config\u001b[38;5;241m.\u001b[39mreturn_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2577\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result\u001b[38;5;241m.\u001b[39mpast_key_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_legacy_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2579\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\transformers\\generation\\utils.py:2784\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2781\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[1;32m-> 2784\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2785\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2786\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\transformers\\utils\\generic.py:918\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[1;32m--> 918\u001b[0m output \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    920\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\transformers\\models\\llava_next\\modeling_llava_next.py:666\u001b[0m, in \u001b[0;36mLlavaNextForConditionalGeneration.forward\u001b[1;34m(self, input_ids, pixel_values, image_sizes, attention_mask, position_ids, past_key_values, inputs_embeds, vision_feature_layer, vision_feature_select_strategy, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m vision_feature_layer \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    658\u001b[0m     vision_feature_layer \u001b[38;5;28;01mif\u001b[39;00m vision_feature_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvision_feature_layer\n\u001b[0;32m    659\u001b[0m )\n\u001b[0;32m    660\u001b[0m vision_feature_select_strategy \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    661\u001b[0m     vision_feature_select_strategy\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vision_feature_select_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvision_feature_select_strategy\n\u001b[0;32m    664\u001b[0m )\n\u001b[1;32m--> 666\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m    667\u001b[0m     input_ids,\n\u001b[0;32m    668\u001b[0m     pixel_values\u001b[38;5;241m=\u001b[39mpixel_values,\n\u001b[0;32m    669\u001b[0m     image_sizes\u001b[38;5;241m=\u001b[39mimage_sizes,\n\u001b[0;32m    670\u001b[0m     vision_feature_layer\u001b[38;5;241m=\u001b[39mvision_feature_layer,\n\u001b[0;32m    671\u001b[0m     vision_feature_select_strategy\u001b[38;5;241m=\u001b[39mvision_feature_select_strategy,\n\u001b[0;32m    672\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    673\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    674\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    675\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m    676\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    677\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    678\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    679\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    680\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    682\u001b[0m )\n\u001b[0;32m    684\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    685\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\transformers\\utils\\generic.py:918\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[1;32m--> 918\u001b[0m output \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    920\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\transformers\\models\\llava_next\\modeling_llava_next.py:507\u001b[0m, in \u001b[0;36mLlavaNextModel.forward\u001b[1;34m(self, input_ids, pixel_values, image_sizes, attention_mask, position_ids, past_key_values, inputs_embeds, vision_feature_layer, vision_feature_select_strategy, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m     special_image_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_placeholder_mask(\n\u001b[0;32m    503\u001b[0m         input_ids, inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds, image_features\u001b[38;5;241m=\u001b[39mimage_features\n\u001b[0;32m    504\u001b[0m     )\n\u001b[0;32m    505\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m inputs_embeds\u001b[38;5;241m.\u001b[39mmasked_scatter(special_image_mask, image_features)\n\u001b[1;32m--> 507\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlanguage_model(\n\u001b[0;32m    508\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    509\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    510\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    511\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m    512\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    513\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    514\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    515\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    516\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    518\u001b[0m )\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LlavaNextModelOutputWithPast(\n\u001b[0;32m    521\u001b[0m     last_hidden_state\u001b[38;5;241m=\u001b[39moutputs\u001b[38;5;241m.\u001b[39mlast_hidden_state,\n\u001b[0;32m    522\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39moutputs\u001b[38;5;241m.\u001b[39mpast_key_values,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    525\u001b[0m     image_hidden_states\u001b[38;5;241m=\u001b[39mimage_features \u001b[38;5;28;01mif\u001b[39;00m pixel_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    526\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\transformers\\utils\\generic.py:1072\u001b[0m, in \u001b[0;36mcheck_model_inputs.<locals>.wrapped_fn.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1069\u001b[0m                 monkey_patched_layers\u001b[38;5;241m.\u001b[39mappend((module, original_forward))\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1072\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[0;32m   1075\u001b[0m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m     kwargs_without_recordable \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:369\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb(hidden_states, position_ids)\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers]:\n\u001b[1;32m--> 369\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[0;32m    370\u001b[0m         hidden_states,\n\u001b[0;32m    371\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[0;32m    372\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    373\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    374\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    375\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    376\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    378\u001b[0m     )\n\u001b[0;32m    379\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(hidden_states)\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[0;32m    381\u001b[0m     last_hidden_state\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[0;32m    382\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:245\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n\u001b[0;32m    244\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m--> 245\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_attention_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[0;32m    247\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\rodar_modelos\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:201\u001b[0m, in \u001b[0;36mMistralRMSNorm.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    199\u001b[0m variance \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    200\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance_epsilon)\n\u001b[1;32m--> 201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m \u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "llava_mix_tm_responses = generate_answers_mix('Tm',mini_llava_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244e2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_llava_df['base_responses'] = pd.Series(llava_base_response)\n",
    "mini_llava_df['mix_tc_responses'] = pd.Series(llava_mix_tc_responses)\n",
    "mini_llava_df['mix_tm_responses'] = pd.Series(llava_mix_tm_responses)\n",
    "mini_llava_df['mix_ti_responses'] = pd.Series(llava_mix_ti_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d650c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_llava_df.to_csv('data/mini_llava_7b_responses.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rodar_modelos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
